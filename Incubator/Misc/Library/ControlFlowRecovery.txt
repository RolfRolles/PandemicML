Congratulations on an accurate and well-reasoned critique.

Indeed, proper disassembly is a major challenge in the formal analysis of binary code, particularly obfuscated code.  The general code/data separation problem [is undecidable](http://comjnl.oxfordjournals.org/content/23/3/223.full.pdf+html).  The problem has come to prominence lately in academic formal verification circles.  Recent approaches to this problem include a combination of overapproximative, abstract interpretation-based methods and those based on theorem proving.

* [An Abstract Interpretation-Based Framework for Control Flow Reconstruction from Binaries](http://www.forsyte.cs.tu-darmstadt.de/~kinder/download.php?t=1&k=vmcai09) and its follow-up [Precise Static Analysis of Untrusted Driver Binaries](http://www.forsyte.cs.tu-darmstadt.de/~kinder/download.php?t=1&k=fmcad10) treat the problem of control-flow recovery as being intertwined with the data analysis that one would normally perform over a fixed control flow graph.  Specifically, control flow graph itself is specified as being the solution to a fixedpoint equation, and the control flow and data fixedpoints are computed simultaneously.  The analysis is parameterized over the data domain, which powers the overapproximative resolve operator, which in turn furnishes a set of locations that each indirect branch may target.  The latter paper introduces an abstract domain that the authors claim is well-suited towards verification of specifications on the API level.

* Approaches specifically targeting obfuscated code are found in [On the Semantics of Self-Unpacking Malware Code](http://www.cs.arizona.edu/~debray/Publications/self-modifying-pgm-semantics.pdf) and a successor paper, [Modelling Metamorphism by Abstract Interpretation](http://www.cs.arizona.edu/~debray/Publications/metamorphic.pdf) (warning: lots and lots of math in the latter).  The former defines a formal semantics for self-modifying programs based.  The language modelled doesn't shy away from real processor features, e.g. memory is modelled as a valuation from addresses to integers, the language supports computed gotos, and instructions must be decoded from integers before their semantics can be determined (which is of course dependent upon the memory state at the time of executing them).  The idea is to partition execution traces along "phase boundaries".  Consider the trace of a self-modifying program.  If at some point on the trace, a location that was previously written is then executed, then the memory image at this point is considered to be a new "program" with an OEP and a given memory state.  Therefore we can map a trace (a sequence of instructions) into a sequence of "programs" that arise at phase boundaries.  We can further organize this information in a graph:  given a sequence of programs P0,P1,P2,..., we add edges in the graph for each adjacent pair:  P0 -> P1, P1 -> P2, and so on.  The precise graph describing the set of all possible modifications is then overapproximated into "the program evolution graph".  The paper then describes a number of applications of program evolution graphs.  The second paper builds upon this framework, overapproximates all possible control flow graphs (dually, in terms of finite state automata) that might arise throughout the course of a program modifying itself, and uses this to detect instances of metamorphic malware (if a program P is a variant of metamorphic family M, then P \sqleq O(M) in the lattice of FSAs, where O(M) denotes the overapproximated program evolution graph).  This stuff is beautiful mathematically, although I have my doubts as to whether we'll ever see incarnations of these ideas in actual malware detectors (partially because of binary alias analysis).

* Now we return to the mundane world of compiler-generated, non-self-modifying code for some very useful and practical results.  beginning with a paper by 

http://www.cs.kent.ac.uk/pubs/2010/3050/content.pdf